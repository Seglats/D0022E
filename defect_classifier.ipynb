{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defect Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('/Users/willekjellberg/.cache/kagglehub/datasets/zhangyunsheng/defects-class-and-location/versions/1')\n",
    "CLASSES = ['crease', 'crescent_gap', 'inclusion', 'oil_spot', 'punching_hole', 'rolled_pit', 'silk_spot']\n",
    "\n",
    "def load(path):\n",
    "    img = cv2.imread(str(path), 0)\n",
    "    if img is None: return None, None\n",
    "    \n",
    "    # Location from XML\n",
    "    xml = DATA / 'label/label' / (path.stem + '.xml')\n",
    "    loc = np.array([0.5, 0.5, 0.5, 0.5], np.float32)\n",
    "    if xml.exists():\n",
    "        try:\n",
    "            root = ET.parse(xml).getroot()\n",
    "            w, h = float(root.find('.//width').text), float(root.find('.//height').text)\n",
    "            box = root.find('.//bndbox')\n",
    "            xmin, ymin = float(box.find('xmin').text)/w, float(box.find('ymin').text)/h\n",
    "            xmax, ymax = float(box.find('xmax').text)/w, float(box.find('ymax').text)/h\n",
    "            loc = np.array([(xmin+xmax)/2, (ymin+ymax)/2, xmax-xmin, ymax-ymin], np.float32)\n",
    "        except: pass\n",
    "    \n",
    "    # Preprocess\n",
    "    mask = img > 10\n",
    "    if mask.any():\n",
    "        r, c = np.where(mask)\n",
    "        img = img[r.min():r.max()+1, c.min():c.max()+1]\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = cv2.createCLAHE(2.0, (8,8)).apply(img).astype(np.float32)\n",
    "    m, s = img.mean(), img.std()\n",
    "    if s > 0: img = (img - m) / s\n",
    "    mn, mx = img.min(), img.max()\n",
    "    if mx > mn: img = (img - mn) / (mx - mn)\n",
    "    return img[..., None], loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1598 images\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "X_img, X_loc, y = [], [], []\n",
    "for i, cls in enumerate(CLASSES):\n",
    "    for p in (DATA / 'images/images' / cls).glob('*.jpg'):\n",
    "        img, loc = load(p)\n",
    "        if img is not None:\n",
    "            X_img.append(img); X_loc.append(loc); y.append(i)\n",
    "\n",
    "X_img, X_loc, y = np.array(X_img), np.array(X_loc), np.array(y)\n",
    "X_img_train, X_img_test, X_loc_train, X_loc_test, y_train, y_test = train_test_split(\n",
    "    X_img, X_loc, y, test_size=0.2, random_state=42, stratify=y)\n",
    "class_weights = {i: len(y_train)/(len(CLASSES)*c) for i,c in enumerate(np.bincount(y_train))}\n",
    "print(f\"Loaded {len(y)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (improved)\n",
    "img_in = layers.Input((128,128,1), name='image')\n",
    "loc_in = layers.Input((4,), name='location')\n",
    "\n",
    "x = layers.RandomRotation(.3)(img_in)\n",
    "x = layers.RandomTranslation(.2,.2)(x)\n",
    "x = layers.RandomZoom(.2)(x)\n",
    "x = layers.RandomFlip('horizontal')(x)\n",
    "\n",
    "# Deeper network with batch norm\n",
    "for f in [32,32,64,64,128,128,256]:\n",
    "    x = layers.Conv2D(f, 3, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    if f in [32,64,128]: x = layers.MaxPooling2D()(x); x = layers.Dropout(.3)(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Stronger location branch\n",
    "loc = layers.Dense(64, 'relu')(layers.Dense(32, 'relu')(loc_in))\n",
    "loc = layers.Dropout(.3)(loc)\n",
    "\n",
    "x = layers.Concatenate()([x, loc])\n",
    "x = layers.Dense(256, 'relu')(x)\n",
    "x = layers.Dropout(.5)(x)\n",
    "x = layers.Dense(128, 'relu')(x)\n",
    "x = layers.Dropout(.5)(x)\n",
    "\n",
    "model = tf.keras.Model([img_in, loc_in], layers.Dense(len(CLASSES), 'softmax')(x))\n",
    "model.compile(tf.keras.optimizers.Adam(1e-3), 'sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.2183 - loss: 1.9125 - val_accuracy: 0.4594 - val_loss: 1.7428 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.3881 - loss: 1.8170 - val_accuracy: 0.4500 - val_loss: 1.6642 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x139d9bdd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "train = tf.data.Dataset.from_tensor_slices(({'image': X_img_train, 'location': X_loc_train}, y_train)).shuffle(2048).batch(32).prefetch(2)\n",
    "val = tf.data.Dataset.from_tensor_slices(({'image': X_img_test, 'location': X_loc_test}, y_test)).batch(32).prefetch(2)\n",
    "\n",
    "model.fit(train, validation_data=val, epochs=int(os.getenv(\"EPOCHS\", \"40\")), class_weight=class_weights,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping('val_accuracy', 20, restore_best_weights=True),\n",
    "               tf.keras.callbacks.ReduceLROnPlateau('val_accuracy', .5, 7, min_lr=1e-7)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.9%\n",
      "\n",
      "Confusion (row=true, col=pred):\n",
      " [[  4   0   0   0   0   0   7]\n",
      " [  2   0   0   0   7   0  36]\n",
      " [  0   0   0   0  26   0  17]\n",
      " [  0   0   0   0  26   0  15]\n",
      " [  0   0   0   0  33   0  11]\n",
      " [  0   0   0   0   0   0   6]\n",
      " [  0   0   0   0  20   0 110]]\n",
      "\n",
      "Normalized:\n",
      " [[0.36 0.   0.   0.   0.   0.   0.64]\n",
      " [0.04 0.   0.   0.   0.16 0.   0.8 ]\n",
      " [0.   0.   0.   0.   0.6  0.   0.4 ]\n",
      " [0.   0.   0.   0.   0.63 0.   0.37]\n",
      " [0.   0.   0.   0.   0.75 0.   0.25]\n",
      " [0.   0.   0.   0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   0.   0.15 0.   0.85]]\n"
     ]
    }
   ],
   "source": [
    "# Eval & confusion matrix\n",
    "acc = model.evaluate({'image': X_img_test, 'location': X_loc_test}, y_test, verbose=0)[1]\n",
    "cm = tf.math.confusion_matrix(y_test, model.predict({'image': X_img_test, 'location': X_loc_test}, verbose=0).argmax(1), len(CLASSES)).numpy()\n",
    "cm_norm = cm / np.maximum(cm.sum(1, keepdims=True), 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for ax, data, title in [(ax1, cm, 'Count'), (ax2, cm_norm, 'Normalized')]:\n",
    "    im = ax.imshow(data, cmap='Blues')\n",
    "    ax.set_xticks(range(len(CLASSES))); ax.set_yticks(range(len(CLASSES)))\n",
    "    ax.set_xticklabels(CLASSES, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(CLASSES)\n",
    "    ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
    "    ax.set_title(f'{title} - Acc: {acc:.1%}')\n",
    "    for i in range(len(CLASSES)):\n",
    "        for j in range(len(CLASSES)):\n",
    "            ax.text(j, i, f'{data[i,j]:.0f}' if title=='Count' else f'{data[i,j]:.2f}',\n",
    "                   ha='center', va='center', color='white' if data[i,j]>data.max()/2 else 'black', fontsize=9)\n",
    "    plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('defect_classifier_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
